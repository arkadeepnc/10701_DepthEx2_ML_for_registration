{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0a90e81e8703646aa16e935f13fa76ea955c3e2d7fb7f046f0a71b0bbf1326d17",
   "display_name": "Python 3.8.8 64-bit ('PyTorch': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "a90e81e8703646aa16e935f13fa76ea955c3e2d7fb7f046f0a71b0bbf1326d17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Toy implementation of the Coherent Point Drift algorithm\n",
    "This implementation is almost entirely based on the [probreg](https://github.com/neka-nat/probreg) repository"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import transforms3d as t3d\n",
    "from probreg import callbacks\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib\n",
    "from collections import namedtuple\n",
    "from probreg import math_utils as mu\n",
    "from probreg import transformation as tf\n",
    "import time\n",
    "from probreg.log import log\n",
    "# import six # just for compatibility "
   ]
  },
  {
   "source": [
    "Import the data and load it as source and template. In this case, we load the data from text and downsample it if needed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PointCloud with 91 points.\nPointCloud with 91 points.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f25f2a5fbe0>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# source, target = utils.prepare_source_and_target_nonrigid_3d('face-x.txt',\n",
    "#                                                              'face-y.txt', 5.0)\n",
    "source, target = utils.prepare_source_and_target_nonrigid_3d('fish-x.txt', 'fish-y.txt', 0.001)\n",
    "source_np = np.asarray(source.points)\n",
    "target_np = np.asarray(target.points)\n",
    "\n",
    "# fig = go.Figure(data=[go.Scatter3d(x=source_np[:,0], y=source_np[:,1], z=source_np[:,2],\n",
    "#                                    mode='markers',    marker=dict( size=1, color='green',  opacity=1.0)), \n",
    "#                                    go.Scatter3d(x=target_np[:,0], y=target_np[:,1], z=target_np[:,2],\n",
    "#                                    mode='markers',    marker=dict( size=1, color='red',  opacity=1.0)) ])\n",
    "# fig.show()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection = '3d')\n",
    "ax.scatter(source_np[:,0], source_np[:,1], source_np[:,2], marker = '.', label = 'source', s = 100.0 )\n",
    "ax.scatter(target_np[:,0], target_np[:,1], target_np[:,2], marker = '*', label = 'target', s = 100.0 )\n",
    "plt.legend()\n",
    "# plt.show()\n",
    "# plt.ion()\n",
    "#  <! ![assasa](face_reg.png) >"
   ]
  },
  {
   "source": [
    "Loaded the data \n",
    "\n",
    "\n",
    "![](fish_data.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We are modelling the target dataset as a mixture of Gaussians centered at the source or measured dataset. \n",
    "\\begin{align}\n",
    "  p(\\mathbf{x}) = w\\frac{1}{N} + (1-w) \\sum_{i=1}^M\\frac{1}{M}\\frac{1}{(2\\pi\\sigma)^{3/2}}\\exp{\\frac{||\\mathbf{x} - \\mathbf{y}_m||^2}{2\\sigma}}  \n",
    "\\end{align}\n",
    "\n",
    "The extra term in the front basically adds a uniform probability distribution to the normal mixture of Gaussians to handle outlier points in the measured data $\\mathbf{x} \\in \\mathbf{X}$\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The motion model updates per point of the source data $\\mathbf{Y}$ as $$\\mathcal{T}(\\mathbf{Y},v) = \\mathbf{Y} + v(\\mathbf{Y})$$, where $v(\\cdot)$ is a point-wise function on the measured data. Influenced by the motion coherence theory, the authors introduce a regularizer to enforce that during the M step, the GMM centroids  $\\in \\mathbf{Y}$ do not scatter in physically impossible ways."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "This section implements the E step -- i.e. solves the correspondence problem. \n",
    "\n",
    "The correspondence matrix $\\mathbf{P} \\in \\mathbb{R}^{M \\times N}$ maps each of the $M$ source points to each of the $N$ target points. We use  $P(m|\\mathbf{x}_n) = P(m)P(\\mathbf{x}_n|m)/p(\\mathbf{x}_n)$ to get the posterior probability distriution. this is exactly similar to the E step of solving a GMM using EM. See [this](https://github.com/nxdens/Depth-Excercise-1-GMM/blob/main/all_depth_ex_plots.ipynb) for more details. \n",
    "\n",
    "$$ \\mathbf{P}_{m,n} = \\dfrac{\\exp \\left( \\frac{-1}{2\\sigma^2} ||\\mathbf{x}_n - (\\mathbf{y}_m + \\mathbf{G}(m,\\cdot)\\mathbf{W})||^2 \\right) } {\\sum_{k=1}^M \\exp \\left( \\frac{-1}{2\\sigma^2} ||\\mathbf{x}_n - (\\mathbf{y}_k + \\mathbf{G}(k,\\cdot)\\mathbf{W})||^2 \\right) + \\frac{w}{1-w} \\frac{(2\\pi\\sigma^2)^{3/2}M}{N} } $$\n",
    "\n",
    "\n",
    "where, $G(\\cdot,\\cdot)$ is the standard radial basis kernel, and $\\mathbf{W}$ is a matrix of coefficients. In this implementation, we use the source points themselves as the coefficients. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EstepResult = namedtuple('EstepResult', ['pt1', 'p1', 'px', 'n_p'])\n",
    "MstepResult = namedtuple('MstepResult', ['transformation', 'sigma2', 'q'])\n",
    "\n",
    "# @six.add_metaclass(abc.ABCMeta)\n",
    "class CoherentPointDrift():\n",
    "    \"\"\"Coherent Point Drift algorithm.\n",
    "    This is an abstract class.\n",
    "    Based on this class, it is inherited by rigid, affine, nonrigid classes\n",
    "    according to the type of transformation.\n",
    "    In this class, Estimation step in EM algorithm is implemented and\n",
    "    Maximazation step is implemented in the inherited classes.\n",
    "\n",
    "    Args:\n",
    "        source (numpy.ndarray, optional): Source point cloud data.\n",
    "        use_cuda (bool, optional): Use CUDA.\n",
    "    \"\"\"\n",
    "    def __init__(self, source=None, use_cuda=False):\n",
    "        self._source = source\n",
    "        self._tf_type = None\n",
    "        self._callbacks = []\n",
    "        if use_cuda:\n",
    "            import cupy as cp\n",
    "            from . import cupy_utils\n",
    "            self.xp = cp\n",
    "            self.cupy_utils = cupy_utils\n",
    "            self._squared_kernel_sum = cupy_utils.squared_kernel_sum\n",
    "        else:\n",
    "            self.xp = np\n",
    "            self._squared_kernel_sum = mu.squared_kernel_sum\n",
    "\n",
    "    def set_source(self, source):\n",
    "        self._source = source\n",
    "\n",
    "    def set_callbacks(self, callbacks):\n",
    "        self._callbacks.extend(callbacks)\n",
    "\n",
    "    # @abc.abstractmethod\n",
    "    def _initialize(self, target):\n",
    "        return MstepResult(None, None, None)\n",
    "\n",
    "    def expectation_step(self, t_source, target, sigma2, w=0.0):\n",
    "        \"\"\"Expectation step for CPD\n",
    "        \"\"\"\n",
    "        assert t_source.ndim == 2 and target.ndim == 2, \"source and target must have 2 dimensions.\"\n",
    "        pmat = self.xp.stack([self.xp.sum(self.xp.square(target - ts), axis=1) for ts in t_source])\n",
    "        pmat = self.xp.exp(-pmat / (2.0 * sigma2))\n",
    "\n",
    "        c = (2.0 * np.pi * sigma2) ** (t_source.shape[1] * 0.5)\n",
    "        c *= w / (1.0 - w) * t_source.shape[0] / target.shape[0]\n",
    "        den = self.xp.sum(pmat, axis=0)\n",
    "        den[den==0] = self.xp.finfo(np.float32).eps\n",
    "        den += c\n",
    "\n",
    "        pmat  = self.xp.divide(pmat, den)\n",
    "        pt1 = self.xp.sum(pmat, axis=0)\n",
    "        p1  = self.xp.sum(pmat, axis=1)\n",
    "        px = self.xp.dot(pmat, target)\n",
    "        return EstepResult(pt1, p1, px, np.sum(p1))\n",
    "\n",
    "    def maximization_step(self, target, estep_res, sigma2_p=None):\n",
    "        return self._maximization_step(self._source, target, estep_res, sigma2_p, xp=self.xp)\n",
    "\n",
    "    @staticmethod\n",
    "    # @abc.abstractmethod\n",
    "    def _maximization_step(source, target, estep_res, sigma2_p=None, xp=np):\n",
    "        return None\n",
    "\n",
    "    def registration(self, target, w=0.0,\n",
    "                     maxiter=50, tol=0.001):\n",
    "        assert not self._tf_type is None, \"transformation type is None.\"\n",
    "        res = self._initialize(target)\n",
    "        q = res.q\n",
    "        for i in range(maxiter):\n",
    "            t_source = res.transformation.transform(self._source)\n",
    "            estep_res = self.expectation_step(t_source, target, res.sigma2, w)\n",
    "            res = self.maximization_step(target, estep_res, res.sigma2)\n",
    "            for c in self._callbacks:\n",
    "                c(res.transformation)\n",
    "            log.debug(\"Iteration: {}, Criteria: {}\".format(i, res.q))\n",
    "            if abs(res.q - q) < tol:\n",
    "                break\n",
    "            q = res.q\n",
    "        return res"
   ]
  },
  {
   "source": [
    "This section implements the M step -- how does the GMM centroids should move to minimize the cost. The steps are :\n",
    "\n",
    "1. Solve for the new weights for the E step\n",
    "$$ (\\mathbf{G}  + d(\\mathbf{P}\\mathbf{1})^{-1}\\lambda \\sigma^2 ) \\mathbf{W}  = d(\\mathbf{P}\\mathbf{1})^{-1}\\mathbf{PX} - Y $$ where $d(\\cdot)^{-1}$ is the inverse diagonal matrix. this is the most expensive part of the CP algorithm\n",
    "\n",
    "2. Solve for the $N_{\\mathbf{P}} = \\sum_m^M \\sum_n^N p(m|\\mathbf{x_m})$ with the previous assignment matrix P $$N_\\mathbf{p} = \\mathbf{1}^T\\mathbf{P1}$$\n",
    "\n",
    "3. Update the means of the GMM -- $$\\mathbf{T} = \\mathbf{Y} + \\mathbf{GW}$$ $$\\mathbf{Y}^{new} = \\mathbf{T} + \\mathbf{Y}^{old}$$\n",
    "\n",
    "4. update the covariance of the mixture models -- This is very close to the M step of the standard GMM solution (e.g. see [this](https://github.com/nxdens/Depth-Excercise-1-GMM/blob/main/all_depth_ex_plots.ipynb))\n",
    "$$\\sigma^2 = \\frac{1}{3N_{\\mathbf{P}}} \\left[\\rm{tr}(\\mathbf{X}^Td(\\mathbf{P}\\mathbf{1})^{-1}\\mathbf{X}) \\right] - 2\\rm{tr}\\left[\\mathbf(PX)^TT\\right] + \\rm{tr}\\left[T^Td(\\mathbf{P}\\mathbf{1})^{-1}T \\right]$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonRigidCPD(CoherentPointDrift):\n",
    "    \"\"\"Coherent Point Drift for nonrigid transformation.\n",
    "\n",
    "    Args:\n",
    "        source (numpy.ndarray, optional): Source point cloud data.\n",
    "        beta (float, optional): Parameter of RBF kernel.\n",
    "        lmd (float, optional): Parameter for regularization term.\n",
    "        use_cuda (bool, optional): Use CUDA.\n",
    "    \"\"\"\n",
    "    def __init__(self, source=None, beta=2.0, lmd=2.0, use_cuda=False):\n",
    "        super(NonRigidCPD, self).__init__(source, use_cuda)\n",
    "        self._tf_type = tf.NonRigidTransformation\n",
    "        self._beta = beta\n",
    "        self._lmd = lmd\n",
    "        self._tf_obj = None\n",
    "        if not self._source is None:\n",
    "            self._tf_obj = self._tf_type(None, self._source, self._beta, self.xp)\n",
    "        self.all_transforms = [] # <-- keep tracks of all the transforms\n",
    "\n",
    "    def set_source(self, source):\n",
    "        self._source = source\n",
    "        self._tf_obj = self._tf_type(None, self._source, self._beta)\n",
    "\n",
    "    def maximization_step(self, target, estep_res, sigma2_p=None):\n",
    "        return self._maximization_step(self._source, target, estep_res,\n",
    "                                       sigma2_p, self._tf_obj, self._lmd, self.xp)\n",
    "\n",
    "    def _initialize(self, target):\n",
    "        dim = self._source.shape[1]\n",
    "        sigma2 = self._squared_kernel_sum(self._source, target)\n",
    "        q = 1.0 + target.shape[0] * dim * 0.5 * np.log(sigma2)\n",
    "        self._tf_obj.w = self.xp.zeros_like(self._source)\n",
    "        return MstepResult(self._tf_obj, sigma2, q)\n",
    "\n",
    "    # @staticmethod\n",
    "    def _maximization_step(self,source, target, estep_res, sigma2_p, tf_obj, lmd, xp=np):\n",
    "        pt1, p1, px, n_p = estep_res\n",
    "        dim = source.shape[1]\n",
    "        w = xp.linalg.solve((p1 * tf_obj.g).T + lmd * sigma2_p * xp.identity(source.shape[0]),\n",
    "                            px - (source.T * p1).T)\n",
    "        t = source + xp.dot(tf_obj.g, w)\n",
    "        tr_xp1x = xp.trace(xp.dot(target.T * pt1, target))\n",
    "        tr_pxt = xp.trace(xp.dot(px.T, t))\n",
    "        tr_tpt = xp.trace(xp.dot(t.T * p1, t))\n",
    "        sigma2 = (tr_xp1x - 2.0 * tr_pxt + tr_tpt) / (n_p * dim)\n",
    "        tf_obj.w = w\n",
    "\n",
    "        self.all_transforms.append(xp.dot(tf_obj.g, tf_obj.w))\n",
    "        return MstepResult(tf_obj, sigma2, sigma2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "Finally, we declear the registration object and run the registration for the given data and plot the results!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "time:0.255011 secs.,   # EM iterations 9\n"
     ]
    }
   ],
   "source": [
    "use_cuda = False \n",
    "cp = np\n",
    "to_cpu = lambda x: x\n",
    "\n",
    "source_pt = cp.asarray(source.points, dtype=cp.float32)\n",
    "target_pt = cp.asarray(target.points, dtype=cp.float32)\n",
    "\n",
    "acpd = NonRigidCPD(source_pt, use_cuda=use_cuda)\n",
    "start = time.time()\n",
    "tf_param, _, _ = acpd.registration(target_pt)\n",
    "elapsed = time.time() - start\n",
    "# print(acpd.all_transforms[0],'<>')\n",
    "print(\"time:{0:2f} secs.,   # EM iterations {1:d}\".format(elapsed, len(acpd.all_transforms)))\n"
   ]
  },
  {
   "source": [
    "Animating every step of the registration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_ = source_pt[:,0:2]\n",
    "tmp_ = target_pt[:,0:2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection = '3d')\n",
    "\n",
    "ax.scatter(target_pt[:,0], target_pt[:,1], marker = '*', label = 'target', s = 100.0)\n",
    "for i in range(9):\n",
    "    src_step = src_ + acpd.all_transforms[i][:,0:2]\n",
    "    ax.scatter(src_step[:,0], src_step[:,1], marker = '.', label = 'src @ step {}'.format(i), s = 50.0)\n",
    "    plt.legend()\n",
    "    # plt.ion()\n",
    "    plt.ioff()\n",
    "    # plt.show()\n",
    "\n",
    "## ---- ## "
   ]
  },
  {
   "source": [
    "The optimization converges in 9 steps and the convergence tracks are visualized below\n",
    "\n",
    "![](fish_tracks.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7fc9f37eaa90>"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# plotting the correspondences found across step a -- b \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection = '3d')\n",
    "\n",
    "a, b = 2, 7 # looks most meaningful\n",
    "\n",
    "ax.scatter(target_pt[:,0], target_pt[:,1], marker = '*', label = 'target', s = 100.0)\n",
    "\n",
    "src_at_step_a = src_ + acpd.all_transforms[a][:,0:2]\n",
    "src_at_step_b = src_ + acpd.all_transforms[b][:,0:2]\n",
    "\n",
    "ax.scatter(src_at_step_a[:,0], src_at_step_a[:,1], marker = 'o', label = 'src @ step {}'.format(a), s = 100.0)\n",
    "ax.scatter(src_at_step_b[:,0], src_at_step_b[:,1], marker = '^', label = 'src @ step {}'.format(b), s = 100.0)\n",
    "U = src_at_step_b[:,0] -  src_at_step_a[:,0]\n",
    "V = src_at_step_b[:,1] -  src_at_step_a[:,1]\n",
    "W = np.zeros_like(U)\n",
    "ax.quiver(src_at_step_a[:,0], src_at_step_a[:,1], np.zeros_like(src_at_step_a[:,1]) , U, V, W, label = 'drift') #, np.ones_like(src_at_step_a[:,1]), 'xy' )\n",
    "plt.legend()\n",
    "plt.ion()\n",
    "# plt.ioff()"
   ]
  },
  {
   "source": [
    "The pointwise drifts between optimization steps 2 and 7 have been visualized \n",
    "\n",
    "![](fish_drift.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}